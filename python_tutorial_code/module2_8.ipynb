{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These session notes from Will may provide answers if some Python functionality provided in Teams does not work...\n",
    "\n",
    "# session_1_data_wrangling.py\n",
    "# https://github.com/data-to-insight/ERN-sessions/blob/main/No%20Local%20Python/session_1_data_wrangling.py\n",
    "\n",
    "# session_1_making_it_an_app.py\n",
    "# https://github.com/data-to-insight/ERN-sessions/blob/main/No%20Local%20Python/session_1_making_it_an_app.py\n",
    "\n",
    "# requirements:  plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96]\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100]\n"
     ]
    }
   ],
   "source": [
    "# list comprehension\n",
    " \n",
    "lc_evens = [num for num in range(1, 101) if (num % 2 == 0) & (num % 3 == 0)]\n",
    "print(lc_evens)\n",
    " \n",
    "# slow, take a lot of lines\n",
    "evens = []\n",
    "for num in range(1, 101):\n",
    "    if num % 2 == 0:\n",
    "        evens.append(num)\n",
    " \n",
    "print(evens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# WHY DOES THIS CELL NOT WORK ????????\n",
    "\n",
    "path = r\"/workspaces/ERN-sessions/no python sessions/data\"\n",
    "\n",
    "# path = r'/workspaces/data-to-insight/ERN-sessions/No Local Python/data'\n",
    "# path = r'\\workspaces\\\\ERN-sessions\\\\No Local Python\\data'\n",
    "# path = r'/workspaces/ERN-sessions/No Local Python/data'\n",
    "# path = 'https://raw.githubusercontent.com/data-to-insight/ERN-sessions/No Local Python/data/b1_children_in_need_2013_to_2024.csv'\n",
    "# filename_2 = 'https://raw.githubusercontent.com/data-to-insight/ERN-sessions/main/data/ChildIdentifiers.csv'\n",
    " \n",
    "files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    " \n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    " \n",
    "    key_string = f.split(\"/\")[-1][:-17]\n",
    "\n",
    "    dfs[key_string] = df\n",
    " \n",
    "print(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {key:dfs[key] for key in sorted(dfs.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'b1_children_in_need_2013_to_2024'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# left_df = dfs['b1_children_in_need']\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m left_df \u001b[38;5;241m=\u001b[39m \u001b[43mdfs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb1_children_in_need_2013_to_2024\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m merge_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(left_df\u001b[38;5;241m.\u001b[39mcolumns[:\u001b[38;5;241m10\u001b[39m])\n\u001b[1;32m      5\u001b[0m new_col_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1_children_in_need_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m merge_cols) \u001b[38;5;28;01melse\u001b[39;00m col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1_children_in_need\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'b1_children_in_need_2013_to_2024'"
     ]
    }
   ],
   "source": [
    "left_df = dfs['b1_children_in_need']\n",
    "# left_df = dfs['b1_children_in_need_2013_to_2024']\n",
    "merge_cols = list(left_df.columns[:10])\n",
    " \n",
    "new_col_names = [f'b1_children_in_need_{col}' if (not col in merge_cols) else col for col in dfs['b1_children_in_need'].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df = left_df.set_axis(new_col_names, axis=1)\n",
    " \n",
    "for key, df in dfs.items():\n",
    "    if (('headline_figures' not in key) &\n",
    "        ('mid-year' not in key) &\n",
    "        ('b1' not in key) &\n",
    "        (key[0] != 'a')):\n",
    " \n",
    "        df = df.set_axis([f'{key}_{col}' if (not col in merge_cols) else col for col in df.columns])\n",
    "       \n",
    "        left_df = left_df.merge(df, how='left', on=merge_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df = left_df.set_axis(new_col_names, axis=1)\n",
    " \n",
    "for key, df in dfs.items():\n",
    "    if (('headline_figures' not in key) &\n",
    "        ('mid-year' not in key) &\n",
    "        ('b1' not in key) &\n",
    "        (key[0] != 'a')):\n",
    " \n",
    "        df = df.set_axis([f'{key}_{col}' if (not col in merge_cols) else col for col in df.columns], axis=1)\n",
    "       \n",
    "        left_df = left_df.merge(df, how='left', on=merge_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    " \n",
    "path = r\"/workspaces/ERN-sessions/no python sessions/data\"\n",
    " \n",
    "files = glob.glob(path+\"/*.csv\")\n",
    " \n",
    "dfs = {}\n",
    " \n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    " \n",
    "    key_string = f.split(\"/\")[-1][:-17]\n",
    " \n",
    "    dfs[key_string] = df\n",
    " \n",
    "dfs = {key:dfs[key] for key in sorted(dfs.keys())}\n",
    " \n",
    "left_df = dfs['b1_children_in_need']\n",
    "merge_cols = list(left_df.columns[:10])\n",
    " \n",
    "new_col_names = [f'b1_children_in_need_{col}' if (not col in merge_cols) else col for col in dfs['b1_children_in_need'].columns]\n",
    "left_df = left_df.set_axis(new_col_names, axis=1)\n",
    " \n",
    "for key, df in dfs.items():\n",
    "    if (('headline_figures' not in key) &\n",
    "        ('mid-year' not in key) &\n",
    "        ('b1' not in key) &\n",
    "        (key[0] != 'a')):\n",
    " \n",
    "        df = df.set_axis([f'{key}_{col}' if (not col in merge_cols) else col for col in df.columns], axis=1)\n",
    "              \n",
    "        left_df = left_df.merge(df, how='left', on=merge_cols)\n",
    " \n",
    "left_df.to_csv('merged_cin.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    " \n",
    "st.title('CIN benchmarking pipeline')\n",
    " \n",
    "files = st.file_uploader(label='Please upload CIN data',\n",
    "                 accept_multiple_files=True)\n",
    " \n",
    "dfs = {}\n",
    " \n",
    "if files:\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    " \n",
    "        key_string = f.name.split(\"/\")[-1][:-17]\n",
    " \n",
    "        dfs[key_string] = df\n",
    " \n",
    "    dfs = {key:dfs[key] for key in sorted(dfs.keys())}\n",
    " \n",
    "    left_df = dfs['b1_children_in_need']\n",
    "    merge_cols = list(left_df.columns[:10])\n",
    " \n",
    "    new_col_names = [f'b1_children_in_need_{col}' if (not col in merge_cols) else col for col in dfs['b1_children_in_need'].columns]\n",
    "    left_df = left_df.set_axis(new_col_names, axis=1)\n",
    " \n",
    "    for key, df in dfs.items():\n",
    "        if (('headline_figures' not in key) &\n",
    "            ('mid-year' not in key) &\n",
    "            ('b1' not in key) &\n",
    "            (key[0] != 'a')):\n",
    "            df = df.set_axis([f'{key}_{col}' if (not col in merge_cols) else col for col in df.columns], axis=1)\n",
    "            left_df = left_df.merge(df, how='left', on=merge_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df(df):\n",
    "    return df.to_csv().encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    " \n",
    "def convert_df(df):\n",
    "    return df.to_csv().encode(\"utf-8\")\n",
    " \n",
    "st.title('CIN benchmarking pipeline')\n",
    " \n",
    "files = st.file_uploader(label='Please upload CIN data',\n",
    "                 accept_multiple_files=True)\n",
    " \n",
    "dfs = {}\n",
    " \n",
    "if files:\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    " \n",
    "        key_string = f.name.split(\"/\")[-1][:-17]\n",
    " \n",
    "        dfs[key_string] = df\n",
    " \n",
    "    dfs = {key:dfs[key] for key in sorted(dfs.keys())}\n",
    " \n",
    "    left_df = dfs['b1_children_in_need']\n",
    "    merge_cols = list(left_df.columns[:10])\n",
    " \n",
    "    new_col_names = [f'b1_children_in_need_{col}' if (not col in merge_cols) else col for col in dfs['b1_children_in_need'].columns]\n",
    "    left_df = left_df.set_axis(new_col_names, axis=1)\n",
    " \n",
    "    for key, df in dfs.items():\n",
    "        if (('headline_figures' not in key) &\n",
    "            ('mid-year' not in key) &\n",
    "            ('b1' not in key) &\n",
    "            (key[0] != 'a')):\n",
    " \n",
    "            df = df.set_axis([f'{key}_{col}' if (not col in merge_cols) else col for col in df.columns], axis=1)\n",
    "           \n",
    "            left_df = left_df.merge(df, how='left', on=merge_cols)\n",
    " \n",
    "    wide_csv = convert_df(left_df)\n",
    " \n",
    "    st.download_button(label='Click to download wide merged data',\n",
    "                       data=wide_csv,\n",
    "                       file_name='wide_benchamrking.csv',\n",
    "                       mime=\"text/csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
