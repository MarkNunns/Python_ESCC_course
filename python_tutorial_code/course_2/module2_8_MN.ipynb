{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These session notes from Will may provide answers if some Python functionality provided in Teams does not work...\n",
    "\n",
    "# session_1_data_wrangling.py\n",
    "# https://github.com/data-to-insight/ERN-sessions/blob/main/No%20Local%20Python/session_1_data_wrangling.py\n",
    "\n",
    "# session_1_making_it_an_app.py\n",
    "# https://github.com/data-to-insight/ERN-sessions/blob/main/No%20Local%20Python/session_1_making_it_an_app.py\n",
    "\n",
    "# requirements:  plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehension\n",
    " \n",
    "lc_evens = [num for num in range(1, 101) if (num % 2 == 0) & (num % 3 == 0)]\n",
    "print(lc_evens)\n",
    " \n",
    "# slow, take a lot of lines\n",
    "evens = []\n",
    "for num in range(1, 101):\n",
    "    if num % 2 == 0:\n",
    "        evens.append(num)\n",
    " \n",
    "print(evens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tricky bit here is accessing a folder full of csv files that are stored in one of Will's Github folders (in the cloud).\n",
    "# One working solution is to copy all the csv files to an MN Github folder.\n",
    "# This path below works, it is a reference to an MN folder in Github.\n",
    "path = r'/workspaces/Python_ESCC_course/python_tutorial_code/course_2/data_mod2_8-9'\n",
    "\n",
    "# The glob.glob() function does not work in a web location (absolute reference starting https:), so don't try to make this work.\n",
    "\n",
    "# Do I have to copy the csv files to an MN Github folder?\n",
    "# To make sure we have these csv files safely kept, # copying them is a good idea anyway.\n",
    "\n",
    "# But can we get this working using Will's Github folder?\n",
    "# path = r'/workspaces/data-to-insight/ERN-sessions/No Local Python/data'\n",
    "# I haven't been able to make this work so far.\n",
    "# Advice from Ben/Declan is that you do have to copy the csv files to your own folder.\n",
    " \n",
    "files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    " \n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    " \n",
    "    key_string = f.split(\"/\")[-1][:-17]\n",
    "\n",
    "    dfs[key_string] = df\n",
    " \n",
    "print(dfs)\n",
    "print(key_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {key:dfs[key] for key in sorted(dfs.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df = dfs['b1_children_in_need']\n",
    "# left_df = dfs['b1_children_in_need_2013_to_2024']\n",
    "merge_cols = list(left_df.columns[:10])\n",
    "\n",
    "new_col_names = [f'b1_children_in_need_{col}' if (not col in merge_cols) else col for col in dfs['b1_children_in_need'].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df = left_df.set_axis(new_col_names, axis=1)\n",
    "\n",
    "for key, df in dfs.items():\n",
    "    if (('headline_figures' not in key) &\n",
    "        ('mid-year' not in key) &\n",
    "        ('b1' not in key) &\n",
    "        (key[0] != 'a')):\n",
    " \n",
    "        df = df.set_axis([f'{key}_{col}' if (not col in merge_cols) else col for col in df.columns], axis=1)\n",
    "        # df = df.set_axis([f'{key}_{col}' if (not col in merge_cols) else col for col in df.columns])\n",
    "\n",
    "        left_df = left_df.merge(df, how='left', on=merge_cols)\n",
    "left_df.to_csv('merged_cin.csv', index=False)\n",
    "print(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell (and all the remaining cells) is not working properly\n",
    "\n",
    "# Go back to previous session where we used Streamlit, it took a while to get that working but it was successful.\n",
    "\n",
    "# in terminal run:   pip install streamlit\n",
    "# Warning: to view this Streamlit app on a browser, run it with the following command:\n",
    "#     streamlit run /home/codespace/.local/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "st.title('Benchmarking data pipeline')\n",
    "\n",
    "# We can use\n",
    "files = st.file_uploader('Please upload benchmarking data', \n",
    "                         accept_multiple_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an empty dictionary to store our dataframes in\n",
    "dfs = {}\n",
    "\n",
    "if files:\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    " \n",
    "        key_string = f.name.split(\"/\")[-1][:-17]\n",
    " \n",
    "        dfs[key_string] = df\n",
    " \n",
    "    dfs = {key:dfs[key] for key in sorted(dfs.keys())}\n",
    " \n",
    "    left_df = dfs['b1_children_in_need']\n",
    "    merge_cols = list(left_df.columns[:10])\n",
    " \n",
    "    new_col_names = [f'b1_children_in_need_{col}' if (not col in merge_cols) else col for col in dfs['b1_children_in_need'].columns]\n",
    "    left_df = left_df.set_axis(new_col_names, axis=1)\n",
    " \n",
    "    for key, df in dfs.items():\n",
    "        if (('headline_figures' not in key) &\n",
    "            ('mid-year' not in key) &\n",
    "            ('b1' not in key) &\n",
    "            (key[0] != 'a')):\n",
    "            df = df.set_axis([f'{key}_{col}' if (not col in merge_cols) else col for col in df.columns], axis=1)\n",
    "            left_df = left_df.merge(df, how='left', on=merge_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df(df):\n",
    "    return df.to_csv().encode(\"utf-8\")\n",
    " \n",
    "st.title('CIN benchmarking pipeline')\n",
    " \n",
    "files = st.file_uploader(label='Please upload CIN data',\n",
    "                 accept_multiple_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an empty dictionary to store our dataframes in\n",
    "dfs = {}\n",
    " \n",
    "if files:\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    " \n",
    "        key_string = f.name.split(\"/\")[-1][:-17]\n",
    " \n",
    "        dfs[key_string] = df\n",
    " \n",
    "    dfs = {key:dfs[key] for key in sorted(dfs.keys())}\n",
    " \n",
    "    left_df = dfs['b1_children_in_need']\n",
    "    merge_cols = list(left_df.columns[:10])\n",
    " \n",
    "    new_col_names = [f'b1_children_in_need_{col}' if (not col in merge_cols) else col for col in dfs['b1_children_in_need'].columns]\n",
    "    left_df = left_df.set_axis(new_col_names, axis=1)\n",
    " \n",
    "    for key, df in dfs.items():\n",
    "        if (('headline_figures' not in key) &\n",
    "            ('mid-year' not in key) &\n",
    "            ('b1' not in key) &\n",
    "            (key[0] != 'a')):\n",
    " \n",
    "            df = df.set_axis([f'{key}_{col}' if (not col in merge_cols) else col for col in df.columns], axis=1)\n",
    "           \n",
    "            left_df = left_df.merge(df, how='left', on=merge_cols)\n",
    " \n",
    "    wide_csv = convert_df(left_df)\n",
    " \n",
    "    st.download_button(label='Click to download wide merged data',\n",
    "                       data=wide_csv,\n",
    "                       file_name='wide_benchamrking.csv',\n",
    "                       mime=\"text/csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
